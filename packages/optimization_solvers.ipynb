{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia Workshop: Optimization and Solvers\n",
    "\n",
    "## @ CEF 2017\n",
    "\n",
    "**Authors**: Chase Coleman and Spencer Lyon\n",
    "\n",
    "**Date**: 27 June 2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "A few different packages used for optimization or non-linear equation solving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QuantEcon\n",
    "\n",
    "The QuantEcon library has a few simple optimizers and solvers. See the economics [notebook](economics.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"QuantEcon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optim.jl\n",
    "\n",
    "Package for optimizing written in pure Julia\n",
    "\n",
    "[Documentation](http://julianlsolvers.github.io/Optim.jl/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"Optim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rosenbrock (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosenbrock(x) = (1.0 - x[1])^2 + 100.0*(x[2] - x[1]^2)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimizing without gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Nelder-Mead\n",
       " * Starting Point: [0.0,0.0]\n",
       " * Minimizer: [0.9999710322210338,0.9999438685860869]\n",
       " * Minimum: 1.164323e-09\n",
       " * Iterations: 74\n",
       " * Convergence: true\n",
       "   *  √(Σ(yᵢ-ȳ)²)/n < 1.0e-08: true\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Calls: 144"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize(rosenbrock, zeros(2), NelderMead())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: BFGS\n",
       " * Starting Point: [0.0,0.0]\n",
       " * Minimizer: [0.9999999926033423,0.9999999852005353]\n",
       " * Minimum: 5.471433e-17\n",
       " * Iterations: 16\n",
       " * Convergence: true\n",
       "   * |x - x'| < 1.0e-32: false \n",
       "     |x - x'| = 3.47e-07 \n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-32: false\n",
       "     |f(x) - f(x')| / |f(x)| = NaN \n",
       "   * |g(x)| < 1.0e-08: true \n",
       "     |g(x)| = 2.33e-09 \n",
       "   * stopped by an increasing objective: false\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Calls: 53\n",
       " * Gradient Calls: 53"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize(rosenbrock, zeros(2), BFGS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimizing with gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rosenbrock_grad! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rosenbrock_grad!(x::Vector, grad::Vector)\n",
    "    grad[1] = -2.0*(1.0 - x[1]) - 400.0*(x[2] - x[1]^2)*x[1]\n",
    "    grad[2] = 200.0*(x[2] - x[1]^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mStorage (g) and evaluation point (x) order has changed. The order is now g!(storage, x) as opposed to the old g!(x, storage). Changing the order and proceeding, but please change your code to use the new syntax.\u001b[39m\u001b[33mStorage (g) and evaluation point (x) order has changed. The order is now fg!(storage, x) as opposed to the old fg!(x, storage). Changing the order and proceeding, but please change your code to use the new syntax.\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: L-BFGS\n",
       " * Starting Point: [0.0,0.0]\n",
       " * Minimizer: [1.0000142961896872,1.0000147679027978]\n",
       " * Minimum: 9.896955e-01\n",
       " * Iterations: 25000\n",
       " * Convergence: false\n",
       "   * |x - x'| < 1.0e-10: false \n",
       "     |x - x'| = 1.55e-09 \n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-09: false\n",
       "     |f(x) - f(x')| / |f(x)| = 1.00e-06 \n",
       "   * |g(x)| < 1.0e-08: false \n",
       "     |g(x)| = 5.56e-03 \n",
       "   * stopped by an increasing objective: true\n",
       "   * Reached Maximum Number of Iterations: true\n",
       " * Objective Calls: 1059533\n",
       " * Gradient Calls: 1059533"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m"
     ]
    }
   ],
   "source": [
    "optimize(rosenbrock, rosenbrock_grad!, zeros(2), LBFGS(),\n",
    "         Optim.Options(x_tol=1e-10, f_tol=1e-9, iterations=25000,\n",
    "                       allow_f_increases=true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mStorage (g) and evaluation point (x) order has changed. The order is now g!(storage, x) as opposed to the old g!(x, storage). Changing the order and proceeding, but please change your code to use the new syntax.\u001b[39m\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mStorage (g) and evaluation point (x) order has changed. The order is now fg!(storage, x) as opposed to the old fg!(x, storage). Changing the order and proceeding, but please change your code to use the new syntax.\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Gradient Descent\n",
       " * Starting Point: [0.0,0.0]\n",
       " * Minimizer: [0.9998054306416495,0.9995907329189162]\n",
       " * Minimum: 9.863819e-01\n",
       " * Iterations: 25000\n",
       " * Convergence: false\n",
       "   * |x - x'| < 1.0e-10: false \n",
       "     |x - x'| = 6.23e-10 \n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-09: false\n",
       "     |f(x) - f(x')| / |f(x)| = NaN \n",
       "   * |g(x)| < 1.0e-08: false \n",
       "     |g(x)| = 7.68e-03 \n",
       "   * stopped by an increasing objective: false\n",
       "   * Reached Maximum Number of Iterations: true\n",
       " * Objective Calls: 1029026\n",
       " * Gradient Calls: 1029026"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize(rosenbrock, rosenbrock_grad!, zeros(2), GradientDescent(),\n",
    "         Optim.Options(x_tol=1e-10, f_tol=1e-9, iterations=25000,\n",
    "                       allow_f_increases=true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimizing with Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rosenbrock_hess! (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rosenbrock_hess!(x::Vector, hess::Matrix)\n",
    "    hess[1, 1] = 2.0 - 400.0 * x[2] + 1200.0*x[1]^2\n",
    "    hess[1, 2] = -400.0 * x[1]\n",
    "    hess[2, 1] = -400.0 * x[1]\n",
    "    hess[2, 2] = 200.0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mStorage and evaluation point order has changed. The syntax is now h!(storage, x) as opposed to the old h!(x, storage). Your Hessian appears to have it the wrong way around. Changing the order and proceeding, but please change your code to use the new syntax.\u001b[39m\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mLinesearch failed, using alpha = 0.0 and exiting optimization.\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Newton's Method\n",
       " * Starting Point: [-0.0,0.0]\n",
       " * Minimizer: [-0.0,0.0]\n",
       " * Minimum: 1.000000e+00\n",
       " * Iterations: 1\n",
       " * Convergence: false\n",
       "   * |x - x'| < 1.0e-32: false \n",
       "     |x - x'| = 0.00e+00 \n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-32: false\n",
       "     |f(x) - f(x')| / |f(x)| = NaN \n",
       "   * |g(x)| < 1.0e-08: false \n",
       "     |g(x)| = 1.00e+00 \n",
       "   * stopped by an increasing objective: false\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Calls: 51\n",
       " * Gradient Calls: 51\n",
       " * Hessian Calls: 1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize(rosenbrock, rosenbrock_grad!, rosenbrock_hess!, zeros(2), Newton())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLopt\n",
    "\n",
    "Julia wrapper to high quality C library.\n",
    "\n",
    "This library has _lots_ of options for algorithms. See [list](http://ab-initio.mit.edu/wiki/index.php/NLopt_Algorithms) of algorithms\n",
    "\n",
    "[Julia package](https://github.com/JuliaOpt/NLopt.jl) and [C Documentation](http://ab-initio.mit.edu/wiki/index.php/NLopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"NLopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using NLopt.optimize in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using NLopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rosenbrock_nlopt (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rosenbrock_nlopt(x::Vector, grad::Vector)\n",
    "    if length(grad) > 0\n",
    "        rosenbrock_grad!(x, grad)\n",
    "    end\n",
    "\n",
    "    return rosenbrock(x)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A non-gradient and gradient based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.251384063527492e-21, [1.0, 1.0], :SUCCESS)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_LBFGS = Opt(:LD_LBFGS, 2)\n",
    "\n",
    "min_objective!(opt_LBFGS, rosenbrock_nlopt)\n",
    "xtol_rel!(opt_LBFGS, 1e-10)\n",
    "ftol_rel!(opt_LBFGS, 1e-9)\n",
    "\n",
    "NLopt.optimize(opt_LBFGS, zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1093356479670479e-29, [1.0, 1.0], :SUCCESS)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_PRAXIS = Opt(:LN_PRAXIS, 2)\n",
    "\n",
    "min_objective!(opt_PRAXIS, rosenbrock_nlopt)\n",
    "\n",
    "NLopt.optimize(opt_PRAXIS, zeros(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A constrained optimization problem\n",
    "\n",
    "\\begin{align*}\n",
    "  \\min_{x_1, x_2} &\\sqrt{x_2} \\\\\n",
    "  &\\text{subject to } \\\\\n",
    "  &x_2 \\geq 0 \\\\\n",
    "  &x_2 \\geq (2 x_1)^3  \\\\\n",
    "  &x_2 \\geq (-x_1 + 1)^3\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myconstraint (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function myfunc(x::Vector, grad::Vector)\n",
    "    if length(grad) > 0\n",
    "        grad[1] = 0\n",
    "        grad[2] = 0.5/sqrt(x[2])\n",
    "    end\n",
    "\n",
    "    return sqrt(x[1] + x[2])\n",
    "end\n",
    "\n",
    "function myconstraint(x::Vector, grad::Vector, a, b)\n",
    "    if length(grad) > 0\n",
    "        grad[1] = 3a * (a*x[1] + b)^2\n",
    "        grad[2] = -1\n",
    "    end\n",
    "\n",
    "    return (a*x[1] + b)^3 - x[2]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 0.7934920514599207 at [0.333333, 0.296296] (returned XTOL_REACHED)\n"
     ]
    }
   ],
   "source": [
    "opt = Opt(:LD_MMA, 2)\n",
    "\n",
    "lower_bounds!(opt, [-Inf, 0.])\n",
    "xtol_rel!(opt, 1e-6)\n",
    "\n",
    "min_objective!(opt, myfunc)\n",
    "\n",
    "inequality_constraint!(opt, (x,g) -> myconstraint(x, g, 2.0, 0.0), 1e-8)\n",
    "inequality_constraint!(opt, (x,g) -> myconstraint(x, g, -1.0 ,1.0), 1e-8)\n",
    "\n",
    "(minf, minx, ret) = NLopt.optimize(opt, [1.234, 5.678])\n",
    "\n",
    "println(\"got $minf at $minx (returned $ret)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NLsolve\n",
    "\n",
    "Julia package written to solve systems of non-linear equations\n",
    "\n",
    "[Documentation](https://github.com/JuliaNLSolvers/NLsolve.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pkg.add(\"NLsolve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using NLsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g! (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f!(xy::Vector, fxy::Vector)\n",
    "    # Pull out arguments\n",
    "    x, y = xy\n",
    "\n",
    "    # Fill fxy\n",
    "    fxy[1] = x^2 - sin(y)\n",
    "    fxy[2] = y^2 - cos(x)\n",
    "end\n",
    "\n",
    "function g!(xy::Vector, jacxy::Matrix)\n",
    "    x, y = xy\n",
    "    # Fill with derivatives of first function\n",
    "    jacxy[1, 1] = 2*x\n",
    "    jacxy[1, 2] = -cos(y)\n",
    "\n",
    "    # Fill off-diagonal\n",
    "    jacxy[2, 1] = sin(x)\n",
    "    jacxy[2, 2] = 2*y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Nonlinear Solver Algorithm\n",
       " * Algorithm: Trust-region with dogleg and autoscaling\n",
       " * Starting Point: [0.5, 0.5]\n",
       " * Zero: [0.8517, 0.811606]\n",
       " * Inf-norm of residuals: 0.000000\n",
       " * Iterations: 5\n",
       " * Convergence: true\n",
       "   * |x - x'| < 0.0e+00: false\n",
       "   * |f(x)| < 1.0e-08: true\n",
       " * Function Calls (f): 6\n",
       " * Jacobian Calls (df/dx): 6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = nlsolve(f!, g!, [0.5, 0.5], ftol=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "white",
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
